# Lex
This is the documentation page for Lex.

## Tokens
To parse language input, Lex's tokenizer begins by reading each character one by one. The tokenizer looks for character sequences -- substrings of the input -- that have a specified meaning. These sequences are called _lexemes_. For example, the input:

~~~tsx
let y = 1;
~~~

comprises five lexemes: `let`, `y`, `=`, `1`, and `;`.

These tokens are defined by an enum:

```tsx
/**
 * An enumerated value corresponding
 * to a token.
 */
enum TOKEN {
    LEFT_PAREN, // Maps to the character "("
    RIGHT_PAREN, // ")"
    LEFT_BRACE, // "{"
    RIGHT_BRACE, // "}"
    COMMA, // ","
    DOT, // "."
    MINUS, // "-"
    PLUS, // "+"
    SEMICOLON, // ";"
    SLASH, // "/"
    STAR, // "*"
    BANG, // "!"
    BANG_EQUAL, // "!="
    EQUAL, // "="
    EQUAL_EQUAL, // "=="
    GREATER, // ">"
    GREATER_EQUAL, // ">="
    LESS, // "<"
    LESS_EQUAL, // "<="
    IDENTIFIER, // A valid name
    STRING, // A valid string value
    INT, // A valid integer value 
    FLOAT, // A valid floating point value
    AND, // Logical operator "and"
    OR, // Logical operator "or"
    NOT, // Logical operator "not"
    CLASS, // Keyword "class"
    FOR, // Keyword "false"
    FN, // Keyword "fn"
    IF, // Keyword "if"
    ELSE, // Keyword "else"
    PRINT, // Keyword "print"
    RETURN, // Keyword "return"
    SUPER, // Keyword "super"
    THIS, // Keyword "this"
    VAR, // Keyword "var"
    WHILE, // Keyword "while"
    FALSE, // Boolean primitive "false"
    TRUE, // Boolean primitive "true"
    NULL, // Primitive "null"
    ERROR, // Utility token for an error
    EOF // Utility token for end-of-file
}
```
 